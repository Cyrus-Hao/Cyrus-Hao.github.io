<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>CyrusHao</title>
        <link>https://Cyrus-hao.github.io/</link>
        <description>Recent content on CyrusHao</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>zh-cn</language>
        <copyright>CyrusHao</copyright>
        <lastBuildDate>Sat, 26 Apr 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://Cyrus-hao.github.io/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>Week9</title>
        <link>https://Cyrus-hao.github.io/p/week9/</link>
        <pubDate>Sat, 26 Apr 2025 00:00:00 +0000</pubDate>
        
        <guid>https://Cyrus-hao.github.io/p/week9/</guid>
        <description>&lt;img src="https://Cyrus-hao.github.io/p/week9/4.24.png" alt="Featured image of post Week9" /&gt;&lt;h2 id=&#34;426&#34;&gt;4.26
&lt;/h2&gt;&lt;p&gt;鼠鼠打算试试申暑研  善良的老师推了zju的一位做3DGS的大牛  遂开始换方向开始3DGS方向的学习  昨晚和做定位的高手学长聊了下  收获满满捏  周六较闲  开始该方向论文的检索&lt;/p&gt;
&lt;h3 id=&#34;vggt-visual-geometry-grounded-transformer&#34;&gt;VGGT: Visual Geometry Grounded Transformer
&lt;/h3&gt;&lt;p&gt;&lt;img src=&#34;https://Cyrus-hao.github.io/p/week9/p3.png&#34;
	width=&#34;738&#34;
	height=&#34;228&#34;
	srcset=&#34;https://Cyrus-hao.github.io/p/week9/p3_hu_79d0df0c61db294a.png 480w, https://Cyrus-hao.github.io/p/week9/p3_hu_1aae8fb97ba46fdd.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;previous works&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;323&#34;
		data-flex-basis=&#34;776px&#34;
	
&gt;              &lt;br&gt;
介绍了一种前馈神经网络VGGT，能够从单个或多个图像视图中直接预测场景的3D属性，包括相机参数、点图、深度图和3D点轨迹。该模型在多个3D任务中表现出色，如相机参数估计、多视图深度估计和密集点云重建，且处理速度快（不到一秒）。               &lt;br&gt;
&lt;img src=&#34;https://Cyrus-hao.github.io/p/week9/p1.png&#34;
	width=&#34;1452&#34;
	height=&#34;478&#34;
	srcset=&#34;https://Cyrus-hao.github.io/p/week9/p1_hu_905b4a5ba117532.png 480w, https://Cyrus-hao.github.io/p/week9/p1_hu_74ed7c00cf1c3f97.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Architecture Overview&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;303&#34;
		data-flex-basis=&#34;729px&#34;
	
&gt;&lt;/p&gt;
&lt;h4 id=&#34;一-输入图像处理&#34;&gt;(一) 输入图像处理
&lt;/h4&gt;&lt;p&gt;&lt;strong&gt;图像分块与特征提取:&lt;/strong&gt;     &lt;br&gt;
VGGT首先将输入图像分成小块，使用DINOv2(选择DINOv2是因为其在训练早期阶段表现更稳定，且对超参数（如学习率和动量）不敏感，相比之下，14×14的卷积层在初期可能不稳定)提取特征生成tokens，并添加位置嵌入以保留空间信息 这一步确保模型能稳定处理图像。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;位置嵌入:&lt;/strong&gt;                        &lt;br&gt;
在tokens上添加位置嵌入 以保留图像的空间关系。这一步对于保持transformer对空间信息的感知至关重要。&lt;/p&gt;
&lt;h4 id=&#34;二-transformer架构&#34;&gt;(二) Transformer架构
&lt;/h4&gt;&lt;p&gt;&lt;strong&gt;交替注意力机制&lt;/strong&gt;：    &lt;br&gt;
模型采用24层的transformer，使用交替注意力机制，交替处理帧内和全局信息。每个注意力层有1024维特征和16个头，类似于DINOv2的ViT-L配置。&lt;/p&gt;
&lt;p&gt;注意力机制交替在帧内（frame-wise）和全局（global）之间工作：      &lt;br&gt;
&lt;strong&gt;帧内注意力：&lt;/strong&gt; 关注单个图像帧内的局部细节，适合捕捉细粒度的特征。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;全局注意力：&lt;/strong&gt; 跨多个视图理解全局场景，适合处理多视图一致性。&lt;/p&gt;
&lt;h4 id=&#34;三-特征提取与上采样&#34;&gt;(三) 特征提取与上采样
&lt;/h4&gt;&lt;p&gt;从特定层(4、11、17和23)提取tokens，通过DPT进行上采样，生成如深度图的高分辨率输出。这一步支持3D属性的精确预测。&lt;/p&gt;
&lt;h4 id=&#34;四-训练数据增强&#34;&gt;(四) 训练数据增强
&lt;/h4&gt;&lt;p&gt;&lt;strong&gt;图像增强技术：&lt;/strong&gt;                  &lt;br&gt;
在训练过程中，随机应用以下增强，以提高模型对各种光照和噪声条件的鲁棒性：&lt;/p&gt;
&lt;p&gt;颜色抖动（Color Jittering）：调整图像的亮度、对比度、饱和度和色调，模拟不同光照条件。&lt;/p&gt;
&lt;p&gt;高斯模糊（Gaussian Blur）：应用模糊效果，模拟真实世界中的成像模糊。&lt;/p&gt;
&lt;p&gt;灰度增强（Grayscale Augmentation）：将图像转换为灰度，测试模型在无颜色信息时的性能。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;图像尺寸调整：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;图像、深度图和点图被等比例调整，使最大维度为518像素。&lt;/p&gt;
&lt;p&gt;较短的维度被裁剪到168~518像素之间，且必须是14像素的倍数，以匹配patchification的patch大小。这一步确保了输入数据的统一性和兼容性。&lt;/p&gt;
&lt;h4 id=&#34;五-总结&#34;&gt;(五) 总结
&lt;/h4&gt;&lt;p&gt;&lt;img src=&#34;https://Cyrus-hao.github.io/p/week9/p2.png&#34;
	width=&#34;1291&#34;
	height=&#34;448&#34;
	srcset=&#34;https://Cyrus-hao.github.io/p/week9/p2_hu_ae0a6be6c3c1cd48.png 480w, https://Cyrus-hao.github.io/p/week9/p2_hu_31d231c88f3d25ed.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;VGGT图像转换方法总结&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;288&#34;
		data-flex-basis=&#34;691px&#34;
	
&gt;&lt;/p&gt;
&lt;h4 id=&#34;pointmap-branch-和-camera-branch&#34;&gt;Pointmap Branch 和 Camera Branch
&lt;/h4&gt;&lt;p&gt;&lt;img src=&#34;https://Cyrus-hao.github.io/p/week9/p4.png&#34;
	width=&#34;1308&#34;
	height=&#34;922&#34;
	srcset=&#34;https://Cyrus-hao.github.io/p/week9/p4_hu_747d2ce27f65867.png 480w, https://Cyrus-hao.github.io/p/week9/p4_hu_e074fa679ab70c15.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Pointmap Branch 和 Camera Branch&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;141&#34;
		data-flex-basis=&#34;340px&#34;
	
&gt;&lt;/p&gt;
&lt;h4 id=&#34;camera-branch&#34;&gt;Camera Branch
&lt;/h4&gt;&lt;p&gt;&lt;img src=&#34;https://Cyrus-hao.github.io/p/week9/p5.png&#34;
	width=&#34;2479&#34;
	height=&#34;1485&#34;
	srcset=&#34;https://Cyrus-hao.github.io/p/week9/p5_hu_a9f202e999261a5d.png 480w, https://Cyrus-hao.github.io/p/week9/p5_hu_e9857fc9977a3e30.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Camera Branch&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;166&#34;
		data-flex-basis=&#34;400px&#34;
	
&gt;&lt;/p&gt;
&lt;h4 id=&#34;pointmap-branch&#34;&gt;Pointmap Branch
&lt;/h4&gt;&lt;p&gt;&lt;img src=&#34;https://Cyrus-hao.github.io/p/week9/p6.png&#34;
	width=&#34;2479&#34;
	height=&#34;1485&#34;
	srcset=&#34;https://Cyrus-hao.github.io/p/week9/p6_hu_4ee3df471952043a.png 480w, https://Cyrus-hao.github.io/p/week9/p6_hu_43b68b685c11255d.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Pointmap Branch&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;166&#34;
		data-flex-basis=&#34;400px&#34;
	
&gt;&lt;/p&gt;
&lt;h4 id=&#34;code&#34;&gt;Code
&lt;/h4&gt;&lt;h5 id=&#34;vggt_to_colmappy&#34;&gt;vggt_to_colmap.py
&lt;/h5&gt;&lt;h6 id=&#34;1-模型加载与推理run_model-函数&#34;&gt;1. 模型加载与推理（run_model 函数）
&lt;/h6&gt;&lt;p&gt;&lt;strong&gt;功能：&lt;/strong&gt;                     &lt;br&gt;
从指定目录加载图像，运行 VGGT 模型推理，生成 3D 点云和相机参数。                 &lt;br&gt;
支持 Pointmap Branch（直接预测 3D 点）和 Depthmap + Camera Branch（通过深度图和相机参数生成点云）。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;images&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;load_and_preprocess_images&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;image_names&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;to&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;device&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;with&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;torch&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;no_grad&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;():&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;k&#34;&gt;with&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;torch&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;cuda&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;amp&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;autocast&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;dtype&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;dtype&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;predictions&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;model&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;images&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;extrinsic&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;intrinsic&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pose_encoding_to_extri_intri&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;predictions&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;pose_enc&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;images&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;shape&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:])&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;depth_map&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;predictions&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;depth&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;world_points&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;unproject_depth_map_to_point_map&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;depth_map&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;predictions&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;extrinsic&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;predictions&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;intrinsic&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;&lt;strong&gt;输入：&lt;/strong&gt;            &lt;br&gt;
图像目录（target_dir/images）中的图像文件。               &lt;br&gt;
&lt;strong&gt;预处理：&lt;/strong&gt;      &lt;br&gt;
通过 load_and_preprocess_images 将图像转换为张量（形状 [S, C, H, W]，S 为图像数量）。                 &lt;br&gt;
&lt;strong&gt;推理：&lt;/strong&gt;            &lt;br&gt;
使用 VGGT 模型生成预测，包括 depth（深度图）、world_points（Pointmap Branch 的 3D 点图）、pose_enc（Camera Branch 的姿态编码）。           &lt;br&gt;
自动混合精度（torch.cuda.amp.autocast）提高推理效率。                            &lt;br&gt;
&lt;strong&gt;后处理：&lt;/strong&gt;            &lt;br&gt;
pose_enc 转换为相机内外参（extrinsic 和 intrinsic）。                  &lt;br&gt;
深度图通过 unproject_depth_map_to_point_map 结合相机参数生成 3D 点（world_points_from_depth）。          &lt;br&gt;
&lt;strong&gt;输出：&lt;/strong&gt;                   &lt;br&gt;
predictions 字典，包含 depth、 world_points、 world_points_from_depth、 extrinsic、 intrinsic 等。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Pointmap Branch：&lt;/strong&gt;          &lt;br&gt;
输出 predictions[&amp;ldquo;world_points&amp;rdquo;]，直接预测每个像素的 3D 坐标（形状 [S, H, W, 3]）。          &lt;br&gt;
在 prediction_mode=&amp;ldquo;Pointmap Regression&amp;rdquo; 时使用。      &lt;br&gt;
&lt;strong&gt;Camera Branch：&lt;/strong&gt;         &lt;br&gt;
输出 predictions[&amp;ldquo;pose_enc&amp;rdquo;]，通过 pose_encoding_to_extri_intri 转换为 extrinsic（4×4 矩阵）和 intrinsic（3×3 矩阵）。         &lt;br&gt;
用于相机姿态估计和深度图到点云的转换。&lt;/p&gt;
&lt;h6 id=&#34;2-文件处理handle_uploads-函数&#34;&gt;2. 文件处理（handle_uploads 函数）
&lt;/h6&gt;&lt;p&gt;&lt;strong&gt;功能：&lt;/strong&gt;                      &lt;br&gt;
处理用户上传的视频或图像，创建临时目录（input_images_&lt;timestamp&gt;），存储图像文件。                &lt;br&gt;
视频会按每秒一帧提取为图像。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;timestamp&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;datetime&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;now&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;strftime&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;%Y%m&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;%d&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;_%H%M%S_&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;%f&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;target_dir&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;sa&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;input_images_&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;timestamp&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;target_dir_images&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;os&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;path&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;join&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;target_dir&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;images&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;input_video&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;is&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;None&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;vs&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;cv2&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;VideoCapture&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;video_path&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;frame_interval&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;int&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;fps&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;  &lt;span class=&#34;c1&#34;&gt;# 1 frame/sec&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;while&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;True&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;gotit&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;frame&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;vs&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;read&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;gotit&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;k&#34;&gt;break&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;count&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;%&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;frame_interval&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;==&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;image_path&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;os&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;path&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;join&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;target_dir_images&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;sa&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;video_frame_num&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;06&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;.png&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;cv2&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;imwrite&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;image_path&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;frame&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;&lt;strong&gt;视频处理：&lt;/strong&gt; 使用 cv2.VideoCapture 按每秒一帧提取图像，保存为 PNG 文件。      &lt;br&gt;
&lt;strong&gt;图像处理：&lt;/strong&gt; 直接复制上传的图像到临时目录。         &lt;br&gt;
&lt;strong&gt;输出：&lt;/strong&gt; 临时目录路径（target_dir）和图像路径列表（image_paths）。         &lt;br&gt;
&lt;strong&gt;作用：&lt;/strong&gt; 为 run_model 提供输入图像目录，确保上传数据格式统一。&lt;/p&gt;
&lt;h6 id=&#34;3-界面更新update_gallery_on_upload-函数&#34;&gt;3. 界面更新（update_gallery_on_upload 函数）
&lt;/h6&gt;&lt;p&gt;&lt;strong&gt;功能：&lt;/strong&gt;             &lt;br&gt;
在用户上传视频或图像时，调用 handle_uploads 处理文件，并更新画廊显示上传的图像。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;input_video&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;and&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;input_images&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;None&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;None&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;None&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;None&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;target_dir&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;image_paths&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;handle_uploads&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;input_video&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;input_images&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;None&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;target_dir&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;image_paths&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;Upload complete. Click &amp;#39;Reconstruct&amp;#39; to begin 3D processing.&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;&lt;strong&gt;逻辑:&lt;/strong&gt; 检查是否有上传内容，若无则返回空值；否则处理文件并返回目录、图像路径和提示信息。             &lt;br&gt;
&lt;strong&gt;输出:&lt;/strong&gt; 更新 Gradio 画廊（image_gallery）和日志（log_output）。&lt;/p&gt;
&lt;h6 id=&#34;4-3d-重建gradio_demo-函数&#34;&gt;4. 3D 重建（gradio_demo 函数）
&lt;/h6&gt;&lt;p&gt;&lt;strong&gt;功能：&lt;/strong&gt;                        &lt;br&gt;
调用 run_model 进行推理，生成 3D 点云和相机参数。        &lt;br&gt;
使用 predictions_to_glb 将预测结果转换为 GLB 文件。            &lt;br&gt;
支持用户调整参数（如置信度阈值、帧过滤、天空分割）。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;predictions&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;run_model&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;target_dir&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;model&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;np&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;savez&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;prediction_save_path&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;**&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;predictions&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;glbscene&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;predictions_to_glb&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;predictions&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;conf_thres&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;conf_thres&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;filter_by_frames&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;frame_filter&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;mask_black_bg&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;mask_black_bg&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;mask_white_bg&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;mask_white_bg&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;show_cam&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;show_cam&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;mask_sky&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;mask_sky&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;target_dir&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;target_dir&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;prediction_mode&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;prediction_mode&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;glbscene&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;export&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;file_obj&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;glbfile&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;&lt;strong&gt;推理：&lt;/strong&gt;  调用 run_model 获取预测。               &lt;br&gt;
&lt;strong&gt;保存：&lt;/strong&gt;  将预测结果保存为 .npz 文件（predictions.npz），便于后续可视化调整。               &lt;br&gt;
&lt;strong&gt;GLB 生成：&lt;/strong&gt;                 &lt;br&gt;
predictions_to_glb 根据 prediction_mode 选择使用 world_points（Pointmap Branch）或 world_points_from_depth（Depthmap + Camera Branch）。                            &lt;br&gt;
应用过滤条件（conf_thres、 mask_sky 等）优化点云。                       &lt;br&gt;
如果 show_cam=True，在 GLB 中显示相机位置。             &lt;br&gt;
&lt;strong&gt;输出：&lt;/strong&gt;  GLB 文件路径（glbfile）、日志信息和更新后的帧选择下拉菜单。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Pointmap Branch：&lt;/strong&gt; &lt;br&gt;
当 prediction_mode=&amp;ldquo;Pointmap Regression&amp;rdquo; 时，使用 predictions[&amp;ldquo;world_points&amp;rdquo;] 作为点云。     &lt;br&gt;
直接提供 3D 坐标，减少对相机参数的依赖。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Camera Branch：&lt;/strong&gt;&lt;br&gt;
提供 extrinsic 和 intrinsic，用于：           &lt;br&gt;
Depthmap 模式下生成 world_points_from_depth。             &lt;br&gt;
在 GLB 中可视化相机位置（show_cam=True）。&lt;/p&gt;
&lt;h6 id=&#34;5-辅助功能&#34;&gt;5. 辅助功能
&lt;/h6&gt;&lt;p&gt;&lt;strong&gt;clear_fields&lt;/strong&gt;：清除 3D 查看器、临时目录和画廊，恢复初始状态。              &lt;br&gt;
&lt;strong&gt;update_log&lt;/strong&gt;：显示“正在加载和重建”提示。             &lt;br&gt;
&lt;strong&gt;update_visualization&lt;/strong&gt;：               &lt;br&gt;
当用户调整参数（如 conf_thres、 frame_filter、 prediction_mode）时，加载保存的 .npz 文件，重新生成 GLB 文件。           &lt;br&gt;
避免重复运行推理，提高交互效率。               &lt;br&gt;
如果是示例数据（is_example=&amp;ldquo;True&amp;rdquo;），提示用户先点击“Reconstruct”。&lt;/p&gt;
</description>
        </item>
        <item>
        <title>前置知识</title>
        <link>https://Cyrus-hao.github.io/p/%E5%89%8D%E7%BD%AE%E7%9F%A5%E8%AF%86/</link>
        <pubDate>Wed, 23 Apr 2025 23:20:21 +0800</pubDate>
        
        <guid>https://Cyrus-hao.github.io/p/%E5%89%8D%E7%BD%AE%E7%9F%A5%E8%AF%86/</guid>
        <description>&lt;img src="https://Cyrus-hao.github.io/p/%E5%89%8D%E7%BD%AE%E7%9F%A5%E8%AF%86/cold_Crime.jpg" alt="Featured image of post 前置知识" /&gt;&lt;h2 id=&#34;部分学习路线&#34;&gt;部分学习路线
&lt;/h2&gt;&lt;p&gt;希望我的学习路线能对大家有所帮助 欢迎批评指正~&lt;/p&gt;
&lt;h3 id=&#34;249---251&#34;&gt;24.9 -&amp;gt; 25.1
&lt;/h3&gt;&lt;p&gt;江科大stm32(上手度高 与正点原子 野火等相比理论略显不足但有较高动手乐趣)   &lt;br&gt;
&lt;a class=&#34;link&#34; href=&#34;https://www.bilibili.com/video/BV1th411z7sn/?spm_id_from=333.337.search-card.all.click&#34;  title=&#34;STM32入门教程-2023版 细致讲解 中文字幕&#34;
     target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;bilibili&lt;/a&gt;  &lt;br&gt;
stm32循迹避障小车(当时买套件学纯代码 可手搓个麦轮小车比买套件有意思)  &lt;br&gt;
PCB绘图(嘉立创)  &lt;br&gt;
&lt;a class=&#34;link&#34; href=&#34;https://www.bilibili.com/video/BV1At421h7Ui/?spm_id_from=333.337.search-card.all.click&#34;  title=&#34;零基础入门PCB设计-国一学长带你学嘉立创EDA专业版 全程保姆级教学 中文字幕（大师篇已更新）&#34;
     target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;bilibili&lt;/a&gt;    &lt;br&gt;
正点原子电机控制(不推荐买课程电机驱动板 容易吃灰)   &lt;br&gt;
&lt;a class=&#34;link&#34; href=&#34;https://www.bilibili.com/video/BV1hv4y1g7s3/?spm_id_from=333.337.search-card.all.click&#34;  title=&#34;【正点原子】手把手教你学STM32电机应用控制&#34;
     target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;bilibili&lt;/a&gt;    &lt;br&gt;
matlab(感觉不用特意去学 数模快到前几天刷一遍就行) &lt;br&gt;
&lt;a class=&#34;link&#34; href=&#34;https://www.youtube.com/playlist?list=PLVHBjRDK0kALcQMwAFbR5q2driYZCHNIx&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;youtube&lt;/a&gt;&lt;br&gt;
24电赛省赛三子棋(视觉部分方法挺多 做着玩锻炼思维 做个完整项目进步还是较快的)  &lt;br&gt;
opencv(不是特别推荐我看的这个 都去看cs231吧haha)    &lt;br&gt;
&lt;a class=&#34;link&#34; href=&#34;https://www.bilibili.com/video/BV1PV411774y/?spm_id_from=333.337.search-card.all.click&amp;amp;vd_source=2f50930509c568406539e7a29e43c090&#34;  title=&#34;【B站最好的OpenCV课程推荐】OpenCV从入门到实战 全套课程&#34;
     target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;bilibili&lt;/a&gt;        &lt;br&gt;
cs231(部分 后期末考试 鸽)     &lt;br&gt;
&lt;a class=&#34;link&#34; href=&#34;https://www.youtube.com/watch?v=vT1JzLTH4G4&amp;amp;list=PL3FW7Lu3i5JvHM8ljYj-zLfQRF3EO8sYv&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;youtube&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;251---252&#34;&gt;25.1 -&amp;gt; 25.2
&lt;/h3&gt;&lt;p&gt;寒假直接忘本 化身纯摆小子hah 别学    &lt;br&gt;
线性代数(吴恩达老师把线代和机器学习混起来讲的 感觉不错 推)    &lt;br&gt;
&lt;a class=&#34;link&#34; href=&#34;https://www.bilibili.com/video/BV1Pg4y1X7Pa/?spm_id_from=333.337.search-card.all.click&#34;  title=&#34;吴恩达《机器学习数学基础（线性代数/微积分）》mathematics-for-machine-learning（中英字幕）&#34;
     target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;bilibili&lt;/a&gt;      &lt;br&gt;
西瓜书(仅仅止步于第三章 去图书馆边看边睡hah 大部分手撕数学原理 不推荐一开始直接去看)     &lt;br&gt;
蓝桥杯嵌入式(力推下面的up 比赛前看的 暑假看的那个模板有一定问题)   &lt;br&gt;
&lt;a class=&#34;link&#34; href=&#34;https://www.bilibili.com/video/BV1wi4y1172U/?spm_id_from=333.1007.top_right_bar_window_custom_collection.content.click&#34;  title=&#34;【备战2025蓝桥杯 嵌入式组】CT117E-M4 新款开发板 3小时省赛模块 速成总结&#34;
     target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;bilibili&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;252---254now&#34;&gt;25.2 -&amp;gt; 25.4(now)
&lt;/h3&gt;&lt;p&gt;机器学习(吴恩达 挺好就是后面字幕有一定问题 会干扰理解)  &lt;br&gt;
&lt;a class=&#34;link&#34; href=&#34;https://www.bilibili.com/video/BV1Bq421A74G/?spm_id_from=333.337.search-card.all.click&#34;  title=&#34;(超爽中英!) 2024公认最好的【吴恩达机器学习】教程！附课件代码 Machine Learning Specialization&#34;
     target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;bilibili&lt;/a&gt;              &lt;br&gt;
鱼书(神经网络部分直观 反向传播等理论通俗易懂 好！)  &lt;br&gt;
pytorch(小土堆 讲的超级棒 重视实践 我把他的视频都刷了遍hah)   &lt;br&gt;
&lt;a class=&#34;link&#34; href=&#34;https://www.bilibili.com/video/BV1hE411t7RN/?spm_id_from=333.1007.top_right_bar_window_custom_collection.content.click&#34;  title=&#34;PyTorch深度学习快速入门教程（绝对通俗易懂！）【小土堆】&#34;
     target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;bilibili&lt;/a&gt;         &lt;br&gt;
强化学习数学原理(公式部分有些看不懂 暂鸽)    &lt;br&gt;
&lt;a class=&#34;link&#34; href=&#34;https://www.bilibili.com/video/BV1sd4y167NS/?spm_id_from=333.337.search-card.all.click&#34;  title=&#34;【强化学习的数学原理】课程：从零开始到透彻理解（完结）&#34;
     target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;bilibili&lt;/a&gt;     &lt;br&gt;
动手学深度学习(在读ing 理论部分清晰 清晰记得当时信息论引入交叉熵豁然开朗)      &lt;br&gt;
李沐带读论文系列(在看ing 沐神还是挺有趣的哈哈) &lt;br&gt;
&lt;a class=&#34;link&#34; href=&#34;https://www.bilibili.com/video/BV1H44y1t75x/?spm_id_from=333.1387.homepage.video_card.click&amp;amp;vd_source=2f50930509c568406539e7a29e43c090&#34;  title=&#34;如何读论文&#34;
     target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;bilibili&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Introduction</title>
        <link>https://Cyrus-hao.github.io/p/introduction/</link>
        <pubDate>Wed, 23 Apr 2025 22:46:08 +0800</pubDate>
        
        <guid>https://Cyrus-hao.github.io/p/introduction/</guid>
        <description>&lt;img src="https://Cyrus-hao.github.io/p/introduction/flower.jpg" alt="Featured image of post Introduction" /&gt;&lt;h2 id=&#34;写在十九岁的起点&#34;&gt;写在十九岁的起点
&lt;/h2&gt;&lt;p&gt;今天是我的19岁生日。没有往年的热闹，我选择静静地为自己留一片空间。它不必完美，或许有些凌乱，或许带着点稚气，但它真实，属于我。高考失利让我来到一所不太理想的大学，可这一学期多以来，遇到的好老师和朋友让我觉得，或许一切自有安排。资源有限，探索新东西时总觉得力不从心，抱怨过，但也只能接受。希望通过写博客，记录生活的点滴，反思自己，一步步走向更远的未来，找回属于我的光，慢慢定义人生。&lt;/p&gt;
</description>
        </item>
        <item>
        <title>归档</title>
        <link>https://Cyrus-hao.github.io/archives/</link>
        <pubDate>Tue, 28 May 2019 00:00:00 +0000</pubDate>
        
        <guid>https://Cyrus-hao.github.io/archives/</guid>
        <description></description>
        </item>
        <item>
        <title>关于</title>
        <link>https://Cyrus-hao.github.io/%E5%85%B3%E4%BA%8E/</link>
        <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
        
        <guid>https://Cyrus-hao.github.io/%E5%85%B3%E4%BA%8E/</guid>
        <description>&lt;p&gt;This is a test page for i18n support.&lt;/p&gt;
</description>
        </item>
        <item>
        <title>搜索</title>
        <link>https://Cyrus-hao.github.io/search/</link>
        <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
        
        <guid>https://Cyrus-hao.github.io/search/</guid>
        <description></description>
        </item>
        <item>
        <title>友情链接</title>
        <link>https://Cyrus-hao.github.io/%E5%8F%8B%E6%83%85%E9%93%BE%E6%8E%A5/</link>
        <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
        
        <guid>https://Cyrus-hao.github.io/%E5%8F%8B%E6%83%85%E9%93%BE%E6%8E%A5/</guid>
        <description>&lt;p&gt;To use this feature, add &lt;code&gt;links&lt;/code&gt; section to frontmatter.&lt;/p&gt;
&lt;p&gt;This page&amp;rsquo;s frontmatter:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;9
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nt&#34;&gt;links&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;title&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;GitHub&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;description&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;GitHub is the world&amp;#39;s largest software development platform.&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;website&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;https://github.com&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;image&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;https://github.githubassets.com/images/modules/logos_page/GitHub-Mark.png&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;title&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;TypeScript&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;description&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;TypeScript is a typed superset of JavaScript that compiles to plain JavaScript.&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;website&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;https://www.typescriptlang.org&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;image&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;ts-logo-128.jpg&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;&lt;code&gt;image&lt;/code&gt; field accepts both local and external images.&lt;/p&gt;
</description>
        </item>
        
    </channel>
</rss>
